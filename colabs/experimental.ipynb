{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experimental.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tiEV3cHhSQ5u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd720fea-f4dc-463d-e5fe-3eaaf2824aa2"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import optimizers\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D, Activation\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import load_model\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "omGnkiSsbZOL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install imgaug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SOd7fODrVyra",
        "colab_type": "code",
        "outputId": "6785bd68-5769-48c5-dcea-b86579647084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O-NBY6mIbktz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# standard augment \n",
        "seq1 = iaa.Sequential([\n",
        "    iaa.Crop(px=(0, 16)), \n",
        "    iaa.Fliplr(0.5), \n",
        "    iaa.GaussianBlur(sigma=(0, 3.0))\n",
        "])\n",
        "\n",
        "# new augment\n",
        "seq2 = iaa.Sequential([\n",
        "    iaa.ContrastNormalization((0.5, 1.5)),\n",
        "    iaa.Sometimes(0.5,\n",
        "        iaa.GaussianBlur(sigma=(0, 0.5))\n",
        "    ),\n",
        "    iaa.Sometimes(0.7, \n",
        "        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)\n",
        "    ),\n",
        "    iaa.Affine(\n",
        "        rotate=(-25, 25),\n",
        "    ),\n",
        "    iaa.Affine(\n",
        "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "    ),\n",
        "    iaa.Affine(\n",
        "        shear=(-25, 25)\n",
        "    ),\n",
        "    \n",
        "    #iaa.Sometimes(0.8, \n",
        "     #   iaa.CoarseDropout(0.03, size_percent=0.1)\n",
        "    #),\n",
        "], random_order=True) # apply augmenters in random order\n",
        "\n",
        "\n",
        "# data augmentation\n",
        "def augment_data_minimal( x_values, y_values ):\n",
        "    counter = 0\n",
        "    RESIZE_DIM = 96\n",
        "    X_values_augmented = []\n",
        "    Y_values_augmented = []\n",
        "    for x in x_values:\n",
        "        for p in range(2):\n",
        "            \n",
        "            # seq 1\n",
        "            Y_values_augmented.append( y_values[counter] )\n",
        "            images_aug = seq_standard.augment_images(x.reshape(1,RESIZE_DIM,RESIZE_DIM,3))   \n",
        "            X_values_augmented.append( images_aug.reshape(RESIZE_DIM,RESIZE_DIM,3))\n",
        "            \n",
        "            # seq 2\n",
        "            Y_values_augmented.append( y_values[counter] )\n",
        "            images_aug = seq_custom.augment_images(x.reshape(1,RESIZE_DIM,RESIZE_DIM,3))   \n",
        "            X_values_augmented.append( images_aug.reshape(RESIZE_DIM,RESIZE_DIM,3))\n",
        "\n",
        "        counter = counter + 1\n",
        "    \n",
        "    \n",
        "    # prev number of images = n\n",
        "    # augmented number of images = n * 4 ( 2 seq 2 times)\n",
        "    X_values_augmented = np.asarray( X_values_augmented )\n",
        "    Y_values_augmented = np.asarray( Y_values_augmented )\n",
        "    return (X_values_augmented, Y_values_augmented)\n",
        "  \n",
        "  \n",
        "  # test time augmentation\n",
        "def test_of_time(x_test):\n",
        "  '''\n",
        "  Arg: x_test: number of test samples of shape (N, w,h,3)\n",
        "  Returns the predicted labels using test time augmentation    \n",
        "  '''\n",
        "  pred_label = []\n",
        "  label = []\n",
        "  # number of samples in test set\n",
        "  l = len(x_test)\n",
        "  for i in range(l):\n",
        "      # normal sample\n",
        "      img = x_test[i]\n",
        "      # augmented sample reshaped(seq acceptd rank-4 tensor) and fed to sequences\n",
        "      img_a = seq1.augment_images(img.reshape(1,RESIZE_DIM,RESIZE_DIM,3))\n",
        "      img_b = seq2.augment_images(img.reshape(1,RESIZE_DIM,RESIZE_DIM,3))\n",
        "      #img_c = seq3.augment_images(img.reshape(1,RESIZE_DIM,RESIZE_DIM,3))\n",
        "\n",
        "      # augmented sample reshaped back in normal(rank-3 tensor)\n",
        "      img_a_out = img_a.reshape(RESIZE_DIM,RESIZE_DIM,3)\n",
        "      img_b_out = img_b.reshape(RESIZE_DIM,RESIZE_DIM,3)\n",
        "      #img_c_out = img_c.reshape(RESIZE_DIM,RESIZE_DIM,3)\n",
        "\n",
        "      # test of time!\n",
        "      y_test1 = model.predict(img_a_out[None,:,:,:])\n",
        "      y_test2 = model.predict(img_b_out[None,:,:,:])\n",
        "      #y_test3 = model.predict(img_c_out[None,:,:,:])\n",
        "      y_test3 = model.predict(img[None,:,:,:])\n",
        "\n",
        "      # change the params in the weighted average equation for minor changes in the performance\n",
        "      # future works: arithmetic mean\n",
        "\n",
        "      # coefficients should add up to 1!\n",
        "      #y_test = .2*y_test1 + .2*y_test2 + .2*y_test3 + .4*y_test4\n",
        "      y_test = .2*y_test1 + .2*y_test2 + .6*y_test3\n",
        "      label.append(y_test)\n",
        "\n",
        "  # convert to final predicted labels\n",
        "  pred_labels=np.concatenate(label)\n",
        "  return pred_labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iCQQ8wiNpNrz",
        "colab_type": "code",
        "outputId": "a46ed480-cfc1-4020-c3d2-478bde036345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Running setup.py bdist_wheel for gputil ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lYyHLk4gb-tK",
        "colab_type": "code",
        "outputId": "044b2db3-eef9-4739-b5b9-71b701b246c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "_kk0_o6Ffkdq",
        "colab_type": "code",
        "outputId": "1a3e372a-894a-470a-fa80-dbf3c0d6f183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan 24 05:16:53 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    58W / 149W |    116MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kMSHONo8igoU",
        "colab_type": "code",
        "outputId": "42878b53-09b8-467a-ae9e-4febf5ac02ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nwaLEhTcSW61",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qsoVbwN9UVNE",
        "colab_type": "code",
        "outputId": "8c15bdea-4b67-4d1b-c1a0-8d9d9cae2788",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dfb0e751-10f1-49db-9420-c9a6af4148d3\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-dfb0e751-10f1-49db-9420-c9a6af4148d3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 67 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nY5PzDDCMVkg",
        "colab_type": "code",
        "outputId": "8d2ad86c-74e1-487d-e4ba-d596db7fa193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cUuuu_vrWAQY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "riPFNpayXg76",
        "colab_type": "code",
        "outputId": "b1f5706d-f64d-4d0c-9e43-38f738df4e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "#!kaggle datasets download -d iarunava/cell-images-for-detecting-malaria\n",
        "!kaggle datasets download -d hasibzunair/malaria"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading malaria.zip to /content\n",
            " 99% 805M/815M [00:11<00:00, 66.0MB/s]\n",
            "100% 815M/815M [00:11<00:00, 72.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2V3kkM-ZX6y_",
        "colab_type": "code",
        "outputId": "b2ab9871-a222-4aac-e955-4cf1b8074d71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json  malaria.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_2vFImCSYCo1",
        "colab_type": "code",
        "outputId": "b04f3489-2c60-4895-a3a5-598ca73a374e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'kaggle.json', 'malaria.zip', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "w4GI7_AIYh7o",
        "colab_type": "code",
        "outputId": "c9576914-87dc-4495-ac45-82949c5ee43f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip 'malaria.zip'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  malaria.zip\n",
            "  inflating: y_test.npy              \n",
            "  inflating: x_test.npy              \n",
            "  inflating: y_train.npy             \n",
            "  inflating: y_val.npy               \n",
            "  inflating: x_train.npy             \n",
            "  inflating: x_val.npy               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vNtyCkIPYjKy",
        "colab_type": "code",
        "outputId": "537bb911-88d5-48ce-d49f-874070329056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json  sample_data  x_train.npy  y_test.npy   y_val.npy\n",
            "malaria.zip  x_test.npy   x_val.npy    y_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gd2kauougikW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# see RAM usage\n",
        "def spec():\n",
        "  GPUs = GPU.getGPUs()\n",
        "  # XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "  gpu = GPUs[0]\n",
        "  def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "  printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WB8fsQ6egNK2",
        "colab_type": "code",
        "outputId": "81c42404-44aa-40bf-c55c-9077cd6d4da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "spec()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.5 GB  | Proc size: 739.2 MB\n",
            "GPU RAM Free: 11325MB | Used: 116MB | Util   1% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7YEH44-4pjyZ",
        "colab_type": "code",
        "outputId": "67e0aa53-04cb-4230-89cb-1ba8c6d952fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = np.load(\"x_train.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((22046, 200, 200, 3), (22046, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "gKzI376uppjH",
        "colab_type": "code",
        "outputId": "7b75a07d-86b8-49b8-c75d-c3aa36e605c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_val = np.load(\"x_val.npy\")\n",
        "y_val = np.load(\"y_val.npy\")\n",
        "x_val.shape, y_val.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2756, 200, 200, 3), (2756, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "z1oTbkw2p2tt",
        "colab_type": "code",
        "outputId": "0a3f6f9e-0fda-4b49-cd65-b02970a9907d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_test = np.load(\"x_test.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "x_test.shape, y_test.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2756, 200, 200, 3), (2756, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "q-vDD60mhPaU",
        "colab_type": "code",
        "outputId": "d3b6c31d-d9de-4e5f-a3f8-690cab981742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "spec()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 9.2 GB  | Proc size: 4.0 GB\n",
            "GPU RAM Free: 11325MB | Used: 116MB | Util   1% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PHebp2hWcRKp",
        "colab_type": "code",
        "outputId": "2b82b51f-624e-447a-b22b-b3eeb81ff9c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, x_test.shape, y_val.shape, y_test.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22046, 200, 200, 3) (22046, 2)\n",
            "(2756, 200, 200, 3) (2756, 200, 200, 3) (2756, 2) (2756, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eThBTtxGfayV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data loaded!"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gHYInTAGqb11",
        "outputId": "91082f29-d611-4f34-83ee-77b0f6081ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = x_train.shape[1]\n",
        "IMAGE_SIZE"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "nCZRZgW8a-3c",
        "colab_type": "code",
        "outputId": "3cf68e30-40be-4140-99f3-f89c3ba3fe55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "files\t     malaria.zip  x_test.npy   x_val.npy   y_train.npy\n",
            "kaggle.json  sample_data  x_train.npy  y_test.npy  y_val.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y1F7A-MqUMwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mkdir files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EDLg0pcTUMc6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cp y_val.npy files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zT2oQiAzUMG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "563c938c-c631-4afb-f577-e8b897b4b563"
      },
      "cell_type": "code",
      "source": [
        "os.listdir(\"files/\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['y_val.npy', 'x_val.npy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "84EhBeWGULz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c9dff25c-a39e-434d-d7a8-2f16d8eaca72"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "files\t     malaria.zip  x_test.npy   x_val.npy   y_train.npy\n",
            "kaggle.json  sample_data  x_train.npy  y_test.npy  y_val.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZCVjeb1CU7Nt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7a1f105c-99cd-4f47-c528-b3643c8f0a7f"
      },
      "cell_type": "code",
      "source": [
        "!zip -r files.zip files"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: files/ (stored 0%)\n",
            "  adding: files/y_val.npy (deflated 96%)\n",
            "  adding: files/x_val.npy (deflated 74%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jEujackzV-3g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "85a66b7b-1311-46ff-c71d-b335f15423e9"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "files\t   kaggle.json\tsample_data  x_train.npy  y_test.npy   y_val.npy\n",
            "files.zip  malaria.zip\tx_test.npy   x_val.npy\t  y_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VOZJHA6OV_Fl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"files.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g4J4GrVRFSDT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "92ce321d-4f57-404a-8f8c-006271b2d89f"
      },
      "cell_type": "code",
      "source": [
        "spec()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 8.4 GB  | Proc size: 5.1 GB\n",
            "GPU RAM Free: 4582MB | Used: 6859MB | Util  60% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gTiAb2ucfhF8",
        "colab_type": "code",
        "outputId": "36c43a25-b2e4-4534-b901-16d5f81f5557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "cell_type": "code",
      "source": [
        "# model with ALL layers frozen, except for the SOFTMAX layer\n",
        "def vgg16():\n",
        "    base_model = VGG16(weights='imagenet',include_top=False,pooling='avg',input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "    base_model.trainable = False\n",
        "    X = base_model.output\n",
        "    X.trainable = False\n",
        "    \n",
        "    #dense = Dense(256, activation='relu')(X)\n",
        "    #dropout_layer = Dropout(0.5)(X)\n",
        "    predictions = Dense(2, activation='softmax')(X)\n",
        "    \n",
        "    # magical line of freezing layers\n",
        "    for layer in base_model.layers[:-5]:\n",
        "        layer.trainable=False\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy']) ##metrics=[precision,recall, f1])\n",
        "    return model\n",
        "\n",
        "model=vgg16()\n",
        "model.summary()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 200, 200, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 200, 200, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 200, 200, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 100, 100, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 100, 100, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 100, 100, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 50, 50, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 50, 50, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 50, 50, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 50, 50, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 25, 25, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 25, 25, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 12, 12, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_7 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 14,715,714\n",
            "Trainable params: 7,080,450\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4ZqXHwe37gRF",
        "colab_type": "code",
        "outputId": "eac902c7-0489-48d7-8329-c579b1cab125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# check input\n",
        "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22046, 200, 200, 3) (22046, 2) (2756, 200, 200, 3) (2756, 2) (2756, 200, 200, 3) (2756, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hQ6YqTRgt6im",
        "colab_type": "code",
        "outputId": "8e7d11d3-1be2-41b4-f48a-df37f22e4356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json  models\t sample_data  x_train.npy  y_test.npy\ty_val.npy\n",
            "malaria.zip  models.zip  x_test.npy   x_val.npy    y_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3EYOO6ust8WZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -f vgg.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C7y6wnac42bZ",
        "colab_type": "code",
        "outputId": "bc12aaf1-f34e-4918-b034-02213609404a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "spec()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 8.4 GB  | Proc size: 5.2 GB\n",
            "GPU RAM Free: 4582MB | Used: 6859MB | Util  60% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y4ikeUhUgKp0",
        "colab_type": "code",
        "outputId": "90cb305c-64e2-471d-ec68-162614534d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "cell_type": "code",
      "source": [
        "model=vgg16()\n",
        "path_model='vgg.h5'  \n",
        "\n",
        "# set the learning rate\n",
        "K.set_value(model.optimizer.lr, 0.001) \n",
        "\n",
        "h=model.fit(x=x_train,     \n",
        "            y=y_train, \n",
        "            batch_size=64, \n",
        "            epochs=50, \n",
        "            verbose=1, \n",
        "            validation_data=(x_val,y_val),\n",
        "            shuffle=True,\n",
        "            callbacks=[\n",
        "                ModelCheckpoint(filepath=path_model),\n",
        "            ]\n",
        "            )\n",
        "\n",
        "# when training few params, VERY SMALL learning rate does not work"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 22046 samples, validate on 2756 samples\n",
            "Epoch 1/50\n",
            "22046/22046 [==============================] - 206s 9ms/step - loss: 0.5538 - acc: 0.8275 - val_loss: 0.2172 - val_acc: 0.9187\n",
            "Epoch 2/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.1843 - acc: 0.9370 - val_loss: 0.1613 - val_acc: 0.9412\n",
            "Epoch 3/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.1495 - acc: 0.9487 - val_loss: 0.1414 - val_acc: 0.9517\n",
            "Epoch 4/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.1338 - acc: 0.9531 - val_loss: 0.1323 - val_acc: 0.9557\n",
            "Epoch 5/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.1234 - acc: 0.9561 - val_loss: 0.1278 - val_acc: 0.9568\n",
            "Epoch 6/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.1166 - acc: 0.9594 - val_loss: 0.1234 - val_acc: 0.9604\n",
            "Epoch 7/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.1113 - acc: 0.9601 - val_loss: 0.1226 - val_acc: 0.9586\n",
            "Epoch 8/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.1064 - acc: 0.9627 - val_loss: 0.1196 - val_acc: 0.9612\n",
            "Epoch 9/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.1019 - acc: 0.9646 - val_loss: 0.1200 - val_acc: 0.9597\n",
            "Epoch 10/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0977 - acc: 0.9650 - val_loss: 0.1157 - val_acc: 0.9619\n",
            "Epoch 11/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0946 - acc: 0.9663 - val_loss: 0.1147 - val_acc: 0.9615\n",
            "Epoch 12/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0914 - acc: 0.9680 - val_loss: 0.1147 - val_acc: 0.9604\n",
            "Epoch 13/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0882 - acc: 0.9691 - val_loss: 0.1135 - val_acc: 0.9626\n",
            "Epoch 14/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0855 - acc: 0.9698 - val_loss: 0.1127 - val_acc: 0.9615\n",
            "Epoch 15/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0830 - acc: 0.9712 - val_loss: 0.1126 - val_acc: 0.9623\n",
            "Epoch 16/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0802 - acc: 0.9718 - val_loss: 0.1113 - val_acc: 0.9612\n",
            "Epoch 17/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0780 - acc: 0.9726 - val_loss: 0.1108 - val_acc: 0.9637\n",
            "Epoch 18/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0757 - acc: 0.9742 - val_loss: 0.1103 - val_acc: 0.9626\n",
            "Epoch 19/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0737 - acc: 0.9745 - val_loss: 0.1105 - val_acc: 0.9637\n",
            "Epoch 20/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0716 - acc: 0.9757 - val_loss: 0.1113 - val_acc: 0.9612\n",
            "Epoch 21/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0694 - acc: 0.9762 - val_loss: 0.1098 - val_acc: 0.9634\n",
            "Epoch 22/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0676 - acc: 0.9777 - val_loss: 0.1092 - val_acc: 0.9637\n",
            "Epoch 23/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0661 - acc: 0.9776 - val_loss: 0.1094 - val_acc: 0.9641\n",
            "Epoch 24/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0644 - acc: 0.9781 - val_loss: 0.1097 - val_acc: 0.9626\n",
            "Epoch 25/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0625 - acc: 0.9790 - val_loss: 0.1091 - val_acc: 0.9641\n",
            "Epoch 26/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0608 - acc: 0.9799 - val_loss: 0.1092 - val_acc: 0.9623\n",
            "Epoch 27/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0593 - acc: 0.9808 - val_loss: 0.1096 - val_acc: 0.9623\n",
            "Epoch 28/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0576 - acc: 0.9812 - val_loss: 0.1090 - val_acc: 0.9634\n",
            "Epoch 29/50\n",
            "22046/22046 [==============================] - 205s 9ms/step - loss: 0.0560 - acc: 0.9818 - val_loss: 0.1094 - val_acc: 0.9648\n",
            "Epoch 30/50\n",
            "16704/22046 [=====================>........] - ETA: 44s - loss: 0.0533 - acc: 0.9826"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w2qN7ElfhH0y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " def plot_loss_accu(history):\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(len(loss))\n",
        "    plt.plot(epochs, loss, 'g')\n",
        "    plt.plot(epochs, val_loss, 'y')\n",
        "    plt.title('Training loss')\n",
        "    plt.legend(['train', 'val'], loc='upper right')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "    loss = history.history['acc']\n",
        "    val_loss = history.history['val_acc']\n",
        "    epochs = range(len(loss))\n",
        "    plt.plot(epochs, loss, 'r')\n",
        "    plt.plot(epochs, val_loss, 'b')\n",
        "    plt.title('Training accuracy')\n",
        "    plt.legend(['train', 'val'], loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "obPywb3KhH6n",
        "colab_type": "code",
        "outputId": "de35bde2-dafc-472f-c120-e6acc8dc46b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "cell_type": "code",
      "source": [
        "plot_loss_accu(h)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0234fe389c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_loss_accu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jcasLX9e9Q09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "505ef347-ac06-43fe-c0c5-961a11cf9c93"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "files\t   kaggle.json\tsample_data  x_test.npy   x_val.npy   y_train.npy\n",
            "files.zip  malaria.zip\tvgg.h5\t     x_train.npy  y_test.npy  y_val.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n6z-ycnmqUbv",
        "colab_type": "code",
        "outputId": "b0113310-cbd4-44e4-a473-57252f53f3ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.13534306543906244\n",
            "Test accuracy: 0.9521044992743106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ub3c15gG39Qp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r models\n",
        "!rm -f models.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0lDOZ-KN1DuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "15cd850d-8931-454f-9674-e73236765982"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json  sample_data  x_test.npy   x_val.npy   y_train.npy\n",
            "malaria.zip  vgg.h5\t  x_train.npy  y_test.npy  y_val.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aIHM3o0f98hC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir models\n",
        "!cp vgg.h5 models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mmb0Bcf69mJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a1341ae-1963-45bb-a649-2ecd49a936f6"
      },
      "cell_type": "code",
      "source": [
        "os.listdir(\"models\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vgg.h5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "UbudFXzE-RuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "839bb066-5592-4af5-dbe2-1f2d18e77b32"
      },
      "cell_type": "code",
      "source": [
        "!zip -r models.zip models"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: models/ (stored 0%)\n",
            "  adding: models/vgg.h5 (deflated 7%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JutrE549-OGo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"models.zip\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ku3vj6N0vyR9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "| Experiments | Train | Val  | Test | Others \n",
        "|------|------|------|------|------|\n",
        "|   Softmax layer train | 93.52 | 93.61 |  93.06 | VGG all layer frozen\n",
        "|   Softmax layer train | 93.52 | 93.61 |  93.46 | Test Time Augmentation\n",
        "|   All layer train   | 96.28| 95.61   | 94.77  | VGG16\n",
        "|   Last 3 layers   | 96.58 | 95.57  | 94.70  | VGG16\n",
        "|   Last 4 layers   | 98.34 | 96.66  | 95.21  | VGG16\n",
        "|   VGG   | xx| xx   | xx  | VGG16\n",
        "|   VGG   | xx | xx  | xx  | VGG16\n",
        "|   VGG   | xx| xx   | xx  | VGG16"
      ]
    },
    {
      "metadata": {
        "id": "vUk_5yHBtY8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jJ_BYhRntZkD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://github.com/alexisbcook/ResNetCAM-keras/blob/master/ResNet_CAM.py"
      ]
    },
    {
      "metadata": {
        "id": "VXnST8VdtBOl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using model.predict(test)"
      ]
    },
    {
      "metadata": {
        "id": "I8BVM7k8glUP",
        "colab_type": "code",
        "outputId": "1fcd99d1-1066-46ee-a2f6-c04f8d2a0bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2756, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "Bd-1OYfsq78P",
        "colab_type": "code",
        "outputId": "c14db339-c542-4f59-fed6-89ea4397142f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# get labels from predictions\n",
        "pred_labels = np.array([np.argmax(pred) for pred in y_pred])\n",
        "pred_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "JBNbvWICrYy3",
        "colab_type": "code",
        "outputId": "d9ca6719-cd39-4b3b-aa7f-42f30374bae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#convert ground truths to column values\n",
        "y_test = np.argmax(y_test, axis=1)\n",
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2756,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "N0no0O9orerc",
        "colab_type": "code",
        "outputId": "6a7b8b60-71c3-4bb3-b0e6-d358478cf09c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# check shape for ground truth and predicted labels\n",
        "y_test.shape, pred_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2756,), (2756,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "RnigGJgVLY-C",
        "colab_type": "code",
        "outputId": "e20ecf44-3981-4f54-b2f7-eafdfe1b90e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x = 93.2504\n",
        "y = 93.4687\n",
        "\n",
        "y-x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21829999999999927"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "uP0OJxO5sg4L",
        "colab_type": "code",
        "outputId": "214b0b5d-c48a-44ee-d5d8-7567fab2f8f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy: ',np.mean((y_test==pred_labels)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9306966618287373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G3YC66xQcr3i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test of time"
      ]
    },
    {
      "metadata": {
        "id": "SwNYI2Rpcs_N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label_pred = test_of_time(x_test)\n",
        "labels.shape\n",
        "\n",
        "\n",
        "# for tta\n",
        "labels= np.array([np.argmax(pred) for pred in label_pred])\n",
        "labels.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_H2mdxwLcvm_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#convert ground truths to column values\n",
        "y_test = np.argmax(y_test, axis=1)\n",
        "y_test.shape\n",
        "\n",
        "\n",
        "\n",
        "# check shape for ground truth and predicted labels: (N,)\n",
        "y_test.shape, labels.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Kzf1CV8cxjy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print('Accuracy with TTA: ',np.mean((y_test==labels)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CKymiS3585_p",
        "colab_type": "code",
        "outputId": "d2bc01bf-c261-4346-e1b4-df1b6a2fcc23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json  sample_data  x_test.npy   x_val.npy   y_train.npy\n",
            "malaria.zip  vgg.h5\t  x_train.npy  y_test.npy  y_val.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t0r2jfpJ86j8",
        "colab_type": "code",
        "outputId": "55b152da-5e8b-4495-95eb-5d320a9de331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "m1 = load_model(\"vgg.h5\")\n",
        "m1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 200, 200, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 200, 200, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 200, 200, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 100, 100, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 100, 100, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 100, 100, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 50, 50, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 50, 50, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 50, 50, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 50, 50, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 25, 25, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 25, 25, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 12, 12, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 14,715,714\n",
            "Trainable params: 2,360,834\n",
            "Non-trainable params: 12,354,880\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DwVX1y_k8-nx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}